

######################################################################
# STARTING FULL TRAINING FOR linear1
# RUN NAME: linear1_2025-11-15_16-53-07
######################################################################

######################################################################
# FULL BACKWARD TRAINING: linear1
######################################################################


======================================================================
TRAINING TIMESTEP n=50/50 (t=1.000)
======================================================================

============================================================
Training timestep n=50 (TERMINAL STEP)
Time: t=1.000, Future models: 0
============================================================
Iter    0: loss=9.637743e-02 | grad=1.5462e+00 | lr=1.00e-02
Iter    1: loss=3.568433e-01 | grad=1.8998e+00 | lr=1.00e-02
Iter    2: loss=2.515628e-01 | grad=1.5029e+00 | lr=1.00e-02
Iter    3: loss=1.055669e-01 | grad=1.1527e+00 | lr=1.00e-02
Iter    4: loss=5.590562e-02 | grad=9.8516e-01 | lr=1.00e-02
Iter    5: loss=7.922654e-02 | grad=1.0198e+00 | lr=1.00e-02
Iter    6: loss=7.030846e-02 | grad=9.9766e-01 | lr=1.00e-02
Iter    7: loss=5.073364e-02 | grad=9.1688e-01 | lr=1.00e-02
Iter    8: loss=3.847978e-02 | grad=8.7162e-01 | lr=1.00e-02
Iter    9: loss=4.017697e-02 | grad=1.0459e+00 | lr=1.00e-02
Iter  100: loss=2.751486e-03 | grad=6.4677e-01 | lr=1.00e-02
Iter  200: loss=2.525320e-03 | grad=1.0933e+00 | lr=1.00e-02
Iter  300: loss=8.107498e-04 | grad=1.0612e+00 | lr=5.00e-03
Iter  400: loss=1.190063e-03 | grad=1.0531e+00 | lr=2.50e-03
Iter  500: loss=1.736753e-04 | grad=8.5975e-01 | lr=1.25e-03
Iter  600: loss=1.009197e-04 | grad=9.2703e-01 | lr=6.25e-04
Iter  700: loss=2.487113e-05 | grad=4.6960e-01 | lr=3.13e-04
Iter  800: loss=2.293158e-05 | grad=3.6505e-01 | lr=1.56e-04
Iter  900: loss=1.800926e-05 | grad=1.9468e-01 | lr=7.81e-05
Iter 1000: loss=1.818953e-05 | grad=2.9367e-02 | lr=3.91e-05
Iter 1100: loss=1.717014e-05 | grad=1.0816e-02 | lr=1.95e-05
Iter 1200: loss=1.762588e-05 | grad=7.0872e-02 | lr=9.77e-06
Iter 1300: loss=1.639019e-05 | grad=1.1277e-02 | lr=2.44e-06
Iter 1400: loss=1.624531e-05 | grad=4.9137e-03 | lr=1.00e-06
✓ Saved loss history for timestep 50 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_50.json

 Final loss: 1.780229e-05
Iterations used: 1500

======================================================================
TRAINING TIMESTEP n=49/50 (t=0.980)
======================================================================

============================================================
Training timestep n=49 (BACKWARD STEP)
Time: t=0.980, Future models: 1
============================================================
Iter    0: loss=5.573393e-02 | grad=2.0437e-01 | lr=9.95e-03
Iter    1: loss=1.067030e-01 | grad=2.6462e-01 | lr=9.95e-03
Iter    2: loss=6.437028e-02 | grad=2.0149e-01 | lr=9.95e-03
Iter    3: loss=5.339592e-02 | grad=4.9299e-01 | lr=9.95e-03
Iter    4: loss=3.692074e-02 | grad=2.1202e-01 | lr=9.95e-03
Iter    5: loss=2.842399e-02 | grad=2.1876e-01 | lr=9.95e-03
Iter    6: loss=2.473235e-02 | grad=1.6113e-01 | lr=9.95e-03
Iter    7: loss=2.197564e-02 | grad=1.4593e-01 | lr=9.95e-03
Iter    8: loss=1.855762e-02 | grad=2.2261e-01 | lr=9.95e-03
Iter    9: loss=1.469387e-02 | grad=5.7928e-01 | lr=9.95e-03
Iter  100: loss=1.836698e-03 | grad=1.2701e-01 | lr=9.95e-03
Iter  200: loss=1.339780e-03 | grad=4.0989e-01 | lr=4.98e-03
Iter  300: loss=7.237408e-04 | grad=6.0207e-01 | lr=2.49e-03
Iter  400: loss=5.564397e-04 | grad=8.6073e-01 | lr=1.24e-03
✓ Saved loss history for timestep 49 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_49.json

 Final loss: 2.569351e-04
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=48/50 (t=0.960)
======================================================================

============================================================
Training timestep n=48 (BACKWARD STEP)
Time: t=0.960, Future models: 2
============================================================
Iter    0: loss=2.325314e-02 | grad=2.5110e-01 | lr=9.90e-03
Iter    1: loss=2.771673e-02 | grad=6.4502e-01 | lr=9.90e-03
Iter    2: loss=7.283437e-02 | grad=5.2731e-01 | lr=9.90e-03
Iter    3: loss=2.016108e-02 | grad=4.5536e-01 | lr=9.90e-03
Iter    4: loss=3.252386e-02 | grad=5.1087e-01 | lr=9.90e-03
Iter    5: loss=1.271845e-02 | grad=4.1457e-01 | lr=9.90e-03
Iter    6: loss=3.997502e-02 | grad=5.8273e-01 | lr=9.90e-03
Iter    7: loss=3.105049e-02 | grad=4.0657e-01 | lr=9.90e-03
Iter    8: loss=1.305509e-02 | grad=7.4139e-01 | lr=9.90e-03
Iter    9: loss=3.709704e-02 | grad=5.6422e-01 | lr=9.90e-03
Iter  100: loss=5.336741e-03 | grad=8.7456e-01 | lr=9.90e-03
Iter  200: loss=2.237346e-03 | grad=4.8957e-01 | lr=4.95e-03
Iter  300: loss=9.349578e-04 | grad=5.5437e-01 | lr=2.48e-03
Iter  400: loss=4.446339e-04 | grad=2.6705e-01 | lr=2.48e-03
✓ Saved loss history for timestep 48 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_48.json

 Final loss: 4.388650e-04
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=47/50 (t=0.940)
======================================================================

============================================================
Training timestep n=47 (BACKWARD STEP)
Time: t=0.940, Future models: 3
============================================================
Iter    0: loss=2.340241e-02 | grad=3.5095e-01 | lr=9.85e-03
Iter    1: loss=4.721897e-02 | grad=7.7637e-01 | lr=9.85e-03
Iter    2: loss=5.967301e-02 | grad=9.1934e-01 | lr=9.85e-03
Iter    3: loss=3.447933e-02 | grad=8.1191e-01 | lr=9.85e-03
Iter    4: loss=1.258604e-02 | grad=4.5330e-01 | lr=9.85e-03
Iter    5: loss=3.315901e-02 | grad=1.0262e+00 | lr=9.85e-03
Iter    6: loss=1.940585e-02 | grad=6.0869e-01 | lr=9.85e-03
Iter    7: loss=2.070253e-02 | grad=9.2269e-01 | lr=9.85e-03
Iter    8: loss=2.058700e-02 | grad=6.2222e-01 | lr=9.85e-03
Iter    9: loss=8.110537e-03 | grad=4.3097e-01 | lr=9.85e-03
Iter  100: loss=3.219546e-03 | grad=7.0844e-01 | lr=9.85e-03
Iter  200: loss=1.844247e-03 | grad=6.7433e-01 | lr=4.93e-03
Iter  300: loss=2.390400e-03 | grad=1.0242e+00 | lr=4.93e-03
Iter  400: loss=8.079560e-04 | grad=8.3566e-01 | lr=2.46e-03
✓ Saved loss history for timestep 47 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_47.json

 Final loss: 5.975004e-04
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=46/50 (t=0.920)
======================================================================

============================================================
Training timestep n=46 (BACKWARD STEP)
Time: t=0.920, Future models: 4
============================================================
Iter    0: loss=2.277039e-02 | grad=4.3487e-01 | lr=9.80e-03
Iter    1: loss=7.231555e-02 | grad=8.5176e-01 | lr=9.80e-03
Iter    2: loss=2.133915e-02 | grad=9.3613e-01 | lr=9.80e-03
Iter    3: loss=3.065651e-02 | grad=9.8987e-01 | lr=9.80e-03
Iter    4: loss=3.333753e-02 | grad=9.6060e-01 | lr=9.80e-03
Iter    5: loss=8.266103e-03 | grad=4.0770e-01 | lr=9.80e-03
Iter    6: loss=2.933442e-02 | grad=9.4904e-01 | lr=9.80e-03
Iter    7: loss=2.374309e-02 | grad=7.8204e-01 | lr=9.80e-03
Iter    8: loss=8.134576e-03 | grad=4.5771e-01 | lr=9.80e-03
Iter    9: loss=1.613644e-02 | grad=1.0529e+00 | lr=9.80e-03
Iter  100: loss=3.189691e-03 | grad=5.8888e-01 | lr=9.80e-03
Iter  200: loss=1.780438e-03 | grad=3.5202e-01 | lr=4.90e-03
Iter  300: loss=8.344795e-04 | grad=2.0871e-01 | lr=2.45e-03
Iter  400: loss=8.646115e-04 | grad=7.8969e-01 | lr=2.45e-03
✓ Saved loss history for timestep 46 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_46.json

 Final loss: 1.100520e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=45/50 (t=0.900)
======================================================================

============================================================
Training timestep n=45 (BACKWARD STEP)
Time: t=0.900, Future models: 5
============================================================
Iter    0: loss=2.690605e-02 | grad=5.4288e-01 | lr=9.75e-03
Iter    1: loss=8.162205e-02 | grad=9.6706e-01 | lr=9.75e-03
Iter    2: loss=2.280677e-02 | grad=1.0874e+00 | lr=9.75e-03
Iter    3: loss=4.118213e-02 | grad=9.2579e-01 | lr=9.75e-03
Iter    4: loss=1.491995e-02 | grad=3.1689e-01 | lr=9.75e-03
Iter    5: loss=4.257913e-02 | grad=9.7981e-01 | lr=9.75e-03
Iter    6: loss=2.289545e-02 | grad=3.2332e-01 | lr=9.75e-03
Iter    7: loss=2.461347e-02 | grad=9.7194e-01 | lr=9.75e-03
Iter    8: loss=2.031047e-02 | grad=7.5571e-01 | lr=9.75e-03
Iter    9: loss=1.079520e-02 | grad=5.4053e-01 | lr=9.75e-03
Iter  100: loss=4.246445e-03 | grad=1.1155e+00 | lr=9.75e-03
Iter  200: loss=2.656596e-03 | grad=6.6264e-01 | lr=4.88e-03
Iter  300: loss=9.381120e-04 | grad=1.0508e-01 | lr=2.44e-03
Iter  400: loss=1.185493e-03 | grad=5.1108e-01 | lr=1.22e-03
✓ Saved loss history for timestep 45 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_45.json

 Final loss: 6.997342e-04
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=44/50 (t=0.880)
======================================================================

============================================================
Training timestep n=44 (BACKWARD STEP)
Time: t=0.880, Future models: 6
============================================================
Iter    0: loss=2.641865e-02 | grad=6.2646e-01 | lr=9.70e-03
Iter    1: loss=9.552386e-02 | grad=1.0730e+00 | lr=9.70e-03
Iter    2: loss=6.040136e-02 | grad=1.0684e+00 | lr=9.70e-03
Iter    3: loss=5.760285e-02 | grad=1.0061e+00 | lr=9.70e-03
Iter    4: loss=2.329249e-02 | grad=8.9460e-01 | lr=9.70e-03
Iter    5: loss=4.311027e-02 | grad=1.0101e+00 | lr=9.70e-03
Iter    6: loss=3.186861e-02 | grad=6.7416e-01 | lr=9.70e-03
Iter    7: loss=2.425378e-02 | grad=1.1081e+00 | lr=9.70e-03
Iter    8: loss=2.875668e-02 | grad=6.1041e-01 | lr=9.70e-03
Iter    9: loss=1.901469e-02 | grad=5.2938e-01 | lr=9.70e-03
Iter  100: loss=4.906171e-03 | grad=4.5349e-01 | lr=9.70e-03
Iter  200: loss=1.658586e-03 | grad=5.7492e-01 | lr=4.85e-03
Iter  300: loss=1.674864e-03 | grad=2.1439e-01 | lr=2.43e-03
Iter  400: loss=1.246013e-03 | grad=3.5824e-01 | lr=2.43e-03
✓ Saved loss history for timestep 44 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_44.json

 Final loss: 1.310403e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=43/50 (t=0.860)
======================================================================

============================================================
Training timestep n=43 (BACKWARD STEP)
Time: t=0.860, Future models: 7
============================================================
Iter    0: loss=2.500195e-02 | grad=8.0715e-01 | lr=9.66e-03
Iter    1: loss=1.199142e-01 | grad=1.1914e+00 | lr=9.66e-03
Iter    2: loss=3.299780e-02 | grad=5.5370e-01 | lr=9.66e-03
Iter    3: loss=5.416929e-02 | grad=5.5400e-01 | lr=9.66e-03
Iter    4: loss=2.945428e-02 | grad=7.4335e-01 | lr=9.66e-03
Iter    5: loss=4.070611e-02 | grad=1.0480e+00 | lr=9.66e-03
Iter    6: loss=1.473436e-02 | grad=4.3555e-01 | lr=9.66e-03
Iter    7: loss=4.007021e-02 | grad=1.2513e+00 | lr=9.66e-03
Iter    8: loss=2.911273e-02 | grad=5.3961e-01 | lr=9.66e-03
Iter    9: loss=3.042852e-02 | grad=1.0803e+00 | lr=9.66e-03
Iter  100: loss=4.403700e-03 | grad=7.6630e-01 | lr=9.66e-03
Iter  200: loss=3.943148e-03 | grad=1.3117e+00 | lr=4.83e-03
Iter  300: loss=1.432659e-03 | grad=1.1019e-01 | lr=2.41e-03
Iter  400: loss=1.758210e-03 | grad=1.0196e+00 | lr=2.41e-03
✓ Saved loss history for timestep 43 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_43.json

 Final loss: 1.135572e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=42/50 (t=0.840)
======================================================================

============================================================
Training timestep n=42 (BACKWARD STEP)
Time: t=0.840, Future models: 8
============================================================
Iter    0: loss=3.289031e-02 | grad=9.2875e-01 | lr=9.61e-03
Iter    1: loss=1.315239e-01 | grad=1.5074e+00 | lr=9.61e-03
Iter    2: loss=5.807162e-02 | grad=1.4950e+00 | lr=9.61e-03
Iter    3: loss=5.028706e-02 | grad=1.1607e+00 | lr=9.61e-03
Iter    4: loss=3.396615e-02 | grad=1.1812e+00 | lr=9.61e-03
Iter    5: loss=2.931723e-02 | grad=1.1448e+00 | lr=9.61e-03
Iter    6: loss=2.076343e-02 | grad=1.0478e+00 | lr=9.61e-03
Iter    7: loss=3.286013e-02 | grad=1.3666e+00 | lr=9.61e-03
Iter    8: loss=2.881933e-02 | grad=1.1242e+00 | lr=9.61e-03
Iter    9: loss=1.596860e-02 | grad=1.0204e+00 | lr=9.61e-03
Iter  100: loss=4.972480e-03 | grad=4.0941e-01 | lr=9.61e-03
Iter  200: loss=4.514372e-03 | grad=7.0791e-01 | lr=4.80e-03
Iter  300: loss=2.747035e-03 | grad=1.1923e+00 | lr=4.80e-03
Iter  400: loss=1.609330e-03 | grad=1.4301e-01 | lr=2.40e-03
✓ Saved loss history for timestep 42 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_42.json

 Final loss: 1.249224e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=41/50 (t=0.820)
======================================================================

============================================================
Training timestep n=41 (BACKWARD STEP)
Time: t=0.820, Future models: 9
============================================================
Iter    0: loss=3.085618e-02 | grad=1.0666e+00 | lr=9.56e-03
Iter    1: loss=1.433692e-01 | grad=1.6037e+00 | lr=9.56e-03
Iter    2: loss=4.595386e-02 | grad=1.1965e+00 | lr=9.56e-03
Iter    3: loss=7.277595e-02 | grad=9.9061e-01 | lr=9.56e-03
Iter    4: loss=4.425104e-02 | grad=1.2915e+00 | lr=9.56e-03
Iter    5: loss=2.839807e-02 | grad=8.1909e-01 | lr=9.56e-03
Iter    6: loss=2.701310e-02 | grad=1.2814e+00 | lr=9.56e-03
Iter    7: loss=3.205162e-02 | grad=1.5439e+00 | lr=9.56e-03
Iter    8: loss=2.357104e-02 | grad=6.7728e-01 | lr=9.56e-03
Iter    9: loss=2.111034e-02 | grad=1.2795e+00 | lr=9.56e-03
Iter  100: loss=5.803584e-03 | grad=1.4748e+00 | lr=9.56e-03
Iter  200: loss=4.337993e-03 | grad=6.8735e-01 | lr=9.56e-03
Iter  300: loss=2.528214e-03 | grad=8.3439e-01 | lr=4.78e-03
Iter  400: loss=3.543513e-03 | grad=1.2608e+00 | lr=4.78e-03
✓ Saved loss history for timestep 41 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_41.json

 Final loss: 1.853856e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=40/50 (t=0.800)
======================================================================

============================================================
Training timestep n=40 (BACKWARD STEP)
Time: t=0.800, Future models: 10
============================================================
Iter    0: loss=2.691399e-02 | grad=1.2333e+00 | lr=9.51e-03
Iter    1: loss=8.830787e-02 | grad=1.8217e+00 | lr=9.51e-03
Iter    2: loss=2.176717e-01 | grad=1.9716e+00 | lr=9.51e-03
Iter    3: loss=4.425522e-02 | grad=5.3822e-01 | lr=9.51e-03
Iter    4: loss=8.732024e-02 | grad=1.7187e+00 | lr=9.51e-03
Iter    5: loss=6.547692e-02 | grad=1.7589e+00 | lr=9.51e-03
Iter    6: loss=1.660613e-02 | grad=1.0461e+00 | lr=9.51e-03
Iter    7: loss=3.207500e-02 | grad=1.2483e+00 | lr=9.51e-03
Iter    8: loss=2.892541e-02 | grad=1.0047e+00 | lr=9.51e-03
Iter    9: loss=2.732821e-02 | grad=1.2470e+00 | lr=9.51e-03
Iter  100: loss=3.947160e-03 | grad=3.6148e-01 | lr=9.51e-03
Iter  200: loss=2.991385e-03 | grad=7.4736e-01 | lr=4.76e-03
Iter  300: loss=2.496094e-03 | grad=4.3171e-01 | lr=4.76e-03
Iter  400: loss=1.980335e-03 | grad=7.7100e-01 | lr=2.38e-03
✓ Saved loss history for timestep 40 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_40.json

 Final loss: 2.531840e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=39/50 (t=0.780)
======================================================================

============================================================
Training timestep n=39 (BACKWARD STEP)
Time: t=0.780, Future models: 11
============================================================
Iter    0: loss=4.156838e-02 | grad=1.4016e+00 | lr=9.46e-03
Iter    1: loss=6.971662e-02 | grad=1.9639e+00 | lr=9.46e-03
Iter    2: loss=3.415466e-01 | grad=2.5847e+00 | lr=9.46e-03
Iter    3: loss=7.672185e-02 | grad=1.7090e+00 | lr=9.46e-03
Iter    4: loss=1.648354e-01 | grad=1.9051e+00 | lr=9.46e-03
Iter    5: loss=1.650614e-01 | grad=1.8652e+00 | lr=9.46e-03
Iter    6: loss=7.768697e-02 | grad=1.7890e+00 | lr=9.46e-03
Iter    7: loss=8.239070e-02 | grad=1.4191e+00 | lr=9.46e-03
Iter    8: loss=8.019180e-02 | grad=1.9245e+00 | lr=9.46e-03
Iter    9: loss=6.380324e-02 | grad=1.2539e+00 | lr=9.46e-03
Iter  100: loss=4.930811e-03 | grad=1.2440e+00 | lr=9.46e-03
Iter  200: loss=3.046241e-03 | grad=2.9149e-01 | lr=4.73e-03
Iter  300: loss=2.292268e-03 | grad=6.8908e-01 | lr=4.73e-03
Iter  400: loss=1.899234e-03 | grad=2.1881e-01 | lr=2.37e-03
✓ Saved loss history for timestep 39 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_39.json

 Final loss: 1.402019e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=38/50 (t=0.760)
======================================================================

============================================================
Training timestep n=38 (BACKWARD STEP)
Time: t=0.760, Future models: 12
============================================================
Iter    0: loss=3.625293e-02 | grad=1.5556e+00 | lr=9.42e-03
Iter    1: loss=1.023647e-01 | grad=2.0599e+00 | lr=9.42e-03
Iter    2: loss=2.483455e-01 | grad=2.3582e+00 | lr=9.42e-03
Iter    3: loss=3.219968e-02 | grad=6.5483e-01 | lr=9.42e-03
Iter    4: loss=1.449523e-01 | grad=2.0257e+00 | lr=9.42e-03
Iter    5: loss=1.134768e-01 | grad=1.9653e+00 | lr=9.42e-03
Iter    6: loss=4.547570e-02 | grad=7.8585e-01 | lr=9.42e-03
Iter    7: loss=4.702939e-02 | grad=2.0050e+00 | lr=9.42e-03
Iter    8: loss=5.108224e-02 | grad=8.6657e-01 | lr=9.42e-03
Iter    9: loss=4.468093e-02 | grad=1.3516e+00 | lr=9.42e-03
Iter  100: loss=6.263913e-03 | grad=1.4364e+00 | lr=9.42e-03
Iter  200: loss=3.276200e-03 | grad=7.2194e-01 | lr=4.71e-03
Iter  300: loss=3.310992e-03 | grad=1.2272e+00 | lr=4.71e-03
Iter  400: loss=1.787552e-03 | grad=2.4738e-01 | lr=2.35e-03
✓ Saved loss history for timestep 38 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_38.json

 Final loss: 1.647133e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=37/50 (t=0.740)
======================================================================

============================================================
Training timestep n=37 (BACKWARD STEP)
Time: t=0.740, Future models: 13
============================================================
Iter    0: loss=3.747868e-02 | grad=1.7234e+00 | lr=9.37e-03
Iter    1: loss=7.145287e-02 | grad=2.1097e+00 | lr=9.37e-03
Iter    2: loss=4.578002e-01 | grad=3.2394e+00 | lr=9.37e-03
Iter    3: loss=9.353961e-02 | grad=2.2825e+00 | lr=9.37e-03
Iter    4: loss=2.107524e-01 | grad=2.1951e+00 | lr=9.37e-03
Iter    5: loss=2.298772e-01 | grad=2.1123e+00 | lr=9.37e-03
Iter    6: loss=1.560984e-01 | grad=2.0671e+00 | lr=9.37e-03
Iter    7: loss=5.577921e-02 | grad=9.2892e-01 | lr=9.37e-03
Iter    8: loss=9.142707e-02 | grad=2.0521e+00 | lr=9.37e-03
Iter    9: loss=9.710062e-02 | grad=9.9015e-01 | lr=9.37e-03
Iter  100: loss=6.545963e-03 | grad=6.0824e-01 | lr=9.37e-03
Iter  200: loss=3.877985e-03 | grad=2.6618e-01 | lr=9.37e-03
Iter  300: loss=3.010069e-03 | grad=7.2722e-01 | lr=4.68e-03
Iter  400: loss=2.291742e-03 | grad=7.4309e-01 | lr=2.34e-03
✓ Saved loss history for timestep 37 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_37.json

 Final loss: 2.133225e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=36/50 (t=0.720)
======================================================================

============================================================
Training timestep n=36 (BACKWARD STEP)
Time: t=0.720, Future models: 14
============================================================
Iter    0: loss=2.938998e-02 | grad=1.8667e+00 | lr=9.32e-03
Iter    1: loss=1.697035e-01 | grad=2.4288e+00 | lr=9.32e-03
Iter    2: loss=2.948165e-01 | grad=2.7464e+00 | lr=9.32e-03
Iter    3: loss=4.192039e-02 | grad=1.4958e+00 | lr=9.32e-03
Iter    4: loss=1.798099e-01 | grad=2.2327e+00 | lr=9.32e-03
Iter    5: loss=1.763287e-01 | grad=2.1597e+00 | lr=9.32e-03
Iter    6: loss=9.608979e-02 | grad=1.9671e+00 | lr=9.32e-03
Iter    7: loss=4.483335e-02 | grad=1.4036e+00 | lr=9.32e-03
Iter    8: loss=7.656581e-02 | grad=2.0903e+00 | lr=9.32e-03
Iter    9: loss=5.349360e-02 | grad=8.1698e-01 | lr=9.32e-03
Iter  100: loss=8.787270e-03 | grad=1.5447e+00 | lr=9.32e-03
Iter  200: loss=4.244234e-03 | grad=8.7748e-01 | lr=9.32e-03
Iter  300: loss=5.047129e-03 | grad=1.2963e+00 | lr=4.66e-03
Iter  400: loss=3.304244e-03 | grad=8.3781e-01 | lr=4.66e-03
✓ Saved loss history for timestep 36 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_36.json

 Final loss: 2.523256e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=35/50 (t=0.700)
======================================================================

============================================================
Training timestep n=35 (BACKWARD STEP)
Time: t=0.700, Future models: 15
============================================================
Iter    0: loss=5.387390e-02 | grad=2.0418e+00 | lr=9.28e-03
Iter    1: loss=6.328067e-02 | grad=2.0043e+00 | lr=9.28e-03
Iter    2: loss=4.037687e-01 | grad=3.1321e+00 | lr=9.28e-03
Iter    3: loss=3.743768e-02 | grad=1.2358e+00 | lr=9.28e-03
Iter    4: loss=2.185073e-01 | grad=2.3544e+00 | lr=9.28e-03
Iter    5: loss=2.119083e-01 | grad=2.2810e+00 | lr=9.28e-03
Iter    6: loss=1.292510e-01 | grad=2.2104e+00 | lr=9.28e-03
Iter    7: loss=1.415949e-01 | grad=1.2287e+00 | lr=9.28e-03
Iter    8: loss=7.633869e-02 | grad=1.8342e+00 | lr=9.28e-03
Iter    9: loss=1.245676e-01 | grad=1.0767e+00 | lr=9.28e-03
Iter  100: loss=1.379656e-02 | grad=2.0296e+00 | lr=9.28e-03
Iter  200: loss=4.120329e-03 | grad=3.7105e-01 | lr=4.64e-03
Iter  300: loss=3.610058e-03 | grad=1.0310e+00 | lr=4.64e-03
Iter  400: loss=2.743398e-03 | grad=3.2442e-01 | lr=2.32e-03
✓ Saved loss history for timestep 35 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_35.json

 Final loss: 2.178797e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=34/50 (t=0.680)
======================================================================

============================================================
Training timestep n=34 (BACKWARD STEP)
Time: t=0.680, Future models: 16
============================================================
Iter    0: loss=4.367994e-02 | grad=2.2015e+00 | lr=9.23e-03
Iter    1: loss=8.549227e-02 | grad=2.5571e+00 | lr=9.23e-03
Iter    2: loss=4.889790e-01 | grad=3.6215e+00 | lr=9.23e-03
Iter    3: loss=1.153069e-01 | grad=2.5393e+00 | lr=9.23e-03
Iter    4: loss=2.239443e-01 | grad=2.5052e+00 | lr=9.23e-03
Iter    5: loss=2.558582e-01 | grad=2.4072e+00 | lr=9.23e-03
Iter    6: loss=1.959005e-01 | grad=2.3570e+00 | lr=9.23e-03
Iter    7: loss=1.070208e-01 | grad=2.1497e+00 | lr=9.23e-03
Iter    8: loss=7.731649e-02 | grad=1.0652e+00 | lr=9.23e-03
Iter    9: loss=1.085561e-01 | grad=2.4357e+00 | lr=9.23e-03
Iter  100: loss=8.787867e-03 | grad=1.6166e+00 | lr=9.23e-03
Iter  200: loss=4.606568e-03 | grad=3.8579e-01 | lr=4.61e-03
Iter  300: loss=4.375586e-03 | grad=7.6890e-01 | lr=4.61e-03
Iter  400: loss=3.023057e-03 | grad=3.8343e-01 | lr=2.31e-03
✓ Saved loss history for timestep 34 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_34.json

 Final loss: 2.654349e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=33/50 (t=0.660)
======================================================================

============================================================
Training timestep n=33 (BACKWARD STEP)
Time: t=0.660, Future models: 17
============================================================
Iter    0: loss=3.180559e-02 | grad=2.3169e+00 | lr=9.18e-03
Iter    1: loss=1.568441e-01 | grad=2.7378e+00 | lr=9.18e-03
Iter    2: loss=3.104792e-01 | grad=3.1177e+00 | lr=9.18e-03
Iter    3: loss=4.458496e-02 | grad=6.7495e-01 | lr=9.18e-03
Iter    4: loss=1.792615e-01 | grad=2.5937e+00 | lr=9.18e-03
Iter    5: loss=1.523291e-01 | grad=2.5425e+00 | lr=9.18e-03
Iter    6: loss=5.700158e-02 | grad=1.1239e+00 | lr=9.18e-03
Iter    7: loss=7.530732e-02 | grad=2.4570e+00 | lr=9.18e-03
Iter    8: loss=7.839719e-02 | grad=1.2357e+00 | lr=9.18e-03
Iter    9: loss=4.344713e-02 | grad=9.6237e-01 | lr=9.18e-03
Iter  100: loss=6.503577e-03 | grad=1.4034e+00 | lr=9.18e-03
Iter  200: loss=4.395558e-03 | grad=2.1344e-01 | lr=4.59e-03
Iter  300: loss=3.993027e-03 | grad=3.0341e-01 | lr=4.59e-03
Iter  400: loss=3.125171e-03 | grad=4.2511e-01 | lr=2.30e-03
✓ Saved loss history for timestep 33 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_33.json

 Final loss: 2.775954e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=32/50 (t=0.640)
======================================================================

============================================================
Training timestep n=32 (BACKWARD STEP)
Time: t=0.640, Future models: 18
============================================================
Iter    0: loss=6.469253e-02 | grad=2.4365e+00 | lr=9.14e-03
Iter    1: loss=1.435069e-01 | grad=2.8823e+00 | lr=9.14e-03
Iter    2: loss=3.220710e-01 | grad=2.8553e+00 | lr=9.14e-03
Iter    3: loss=7.060377e-02 | grad=1.8389e+00 | lr=9.14e-03
Iter    4: loss=1.909223e-01 | grad=2.6728e+00 | lr=9.14e-03
Iter    5: loss=1.858898e-01 | grad=2.6289e+00 | lr=9.14e-03
Iter    6: loss=8.068936e-02 | grad=2.5670e+00 | lr=9.14e-03
Iter    7: loss=8.802795e-02 | grad=2.2133e+00 | lr=9.14e-03
Iter    8: loss=1.002131e-01 | grad=2.5937e+00 | lr=9.14e-03
Iter    9: loss=5.135313e-02 | grad=7.0856e-01 | lr=9.14e-03
Iter  100: loss=6.689100e-03 | grad=1.3936e+00 | lr=9.14e-03
Iter  200: loss=5.115610e-03 | grad=1.0374e+00 | lr=4.57e-03
Iter  300: loss=4.673255e-03 | grad=1.3519e+00 | lr=4.57e-03
Iter  400: loss=3.038137e-03 | grad=4.9739e-01 | lr=2.28e-03
✓ Saved loss history for timestep 32 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_32.json

 Final loss: 2.912706e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=31/50 (t=0.620)
======================================================================

============================================================
Training timestep n=31 (BACKWARD STEP)
Time: t=0.620, Future models: 19
============================================================
Iter    0: loss=5.061881e-02 | grad=2.5523e+00 | lr=9.09e-03
Iter    1: loss=1.111519e-01 | grad=2.8815e+00 | lr=9.09e-03
Iter    2: loss=3.913273e-01 | grad=3.3576e+00 | lr=9.09e-03
Iter    3: loss=8.668096e-02 | grad=2.2071e+00 | lr=9.09e-03
Iter    4: loss=2.049854e-01 | grad=2.7623e+00 | lr=9.09e-03
Iter    5: loss=2.159071e-01 | grad=2.7011e+00 | lr=9.09e-03
Iter    6: loss=1.337120e-01 | grad=2.6966e+00 | lr=9.09e-03
Iter    7: loss=4.310638e-02 | grad=6.6330e-01 | lr=9.09e-03
Iter    8: loss=1.017374e-01 | grad=2.8338e+00 | lr=9.09e-03
Iter    9: loss=6.121693e-02 | grad=6.6714e-01 | lr=9.09e-03
Iter  100: loss=1.117772e-02 | grad=1.8565e+00 | lr=9.09e-03
Iter  200: loss=6.696846e-03 | grad=1.5687e+00 | lr=9.09e-03
Iter  300: loss=4.492257e-03 | grad=2.8559e-01 | lr=4.55e-03
Iter  400: loss=4.665989e-03 | grad=4.8916e-01 | lr=4.55e-03
✓ Saved loss history for timestep 31 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_31.json

 Final loss: 3.046745e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=30/50 (t=0.600)
======================================================================

============================================================
Training timestep n=30 (BACKWARD STEP)
Time: t=0.600, Future models: 20
============================================================
Iter    0: loss=3.487116e-02 | grad=2.6462e+00 | lr=9.05e-03
Iter    1: loss=1.108850e-01 | grad=3.0124e+00 | lr=9.05e-03
Iter    2: loss=4.078024e-01 | grad=3.7159e+00 | lr=9.05e-03
Iter    3: loss=7.196894e-02 | grad=1.6397e+00 | lr=9.05e-03
Iter    4: loss=2.339149e-01 | grad=2.9503e+00 | lr=9.05e-03
Iter    5: loss=2.179892e-01 | grad=2.8703e+00 | lr=9.05e-03
Iter    6: loss=9.923577e-02 | grad=2.6713e+00 | lr=9.05e-03
Iter    7: loss=9.329696e-02 | grad=2.3957e+00 | lr=9.05e-03
Iter    8: loss=7.569644e-02 | grad=2.2983e+00 | lr=9.05e-03
Iter    9: loss=1.033118e-01 | grad=2.9589e+00 | lr=9.05e-03
Iter  100: loss=6.877985e-03 | grad=1.0072e+00 | lr=9.05e-03
Iter  200: loss=9.058028e-03 | grad=1.7345e+00 | lr=9.05e-03
Iter  300: loss=4.097649e-03 | grad=2.1543e-01 | lr=4.52e-03
Iter  400: loss=4.980057e-03 | grad=1.5995e+00 | lr=4.52e-03
✓ Saved loss history for timestep 30 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_30.json

 Final loss: 3.736744e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=29/50 (t=0.580)
======================================================================

============================================================
Training timestep n=29 (BACKWARD STEP)
Time: t=0.580, Future models: 21
============================================================
Iter    0: loss=6.833959e-02 | grad=2.7200e+00 | lr=9.00e-03
Iter    1: loss=2.499849e-01 | grad=3.1441e+00 | lr=9.00e-03
Iter    2: loss=6.738295e-02 | grad=2.2652e+00 | lr=9.00e-03
Iter    3: loss=9.378640e-02 | grad=2.8167e+00 | lr=9.00e-03
Iter    4: loss=5.238121e-02 | grad=1.1153e+00 | lr=9.00e-03
Iter    5: loss=6.129144e-02 | grad=2.4783e+00 | lr=9.00e-03
Iter    6: loss=6.384684e-02 | grad=9.5045e-01 | lr=9.00e-03
Iter    7: loss=2.701816e-02 | grad=1.7908e+00 | lr=9.00e-03
Iter    8: loss=4.916749e-02 | grad=9.4561e-01 | lr=9.00e-03
Iter    9: loss=3.947809e-02 | grad=9.5622e-01 | lr=9.00e-03
Iter  100: loss=5.509822e-03 | grad=2.7885e-01 | lr=9.00e-03
Iter  200: loss=1.339131e-02 | grad=2.5640e+00 | lr=9.00e-03
Iter  300: loss=4.519112e-03 | grad=1.6019e+00 | lr=4.50e-03
Iter  400: loss=3.239634e-03 | grad=3.3931e-01 | lr=2.25e-03
✓ Saved loss history for timestep 29 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_29.json

 Final loss: 2.804904e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=28/50 (t=0.560)
======================================================================

============================================================
Training timestep n=28 (BACKWARD STEP)
Time: t=0.560, Future models: 22
============================================================
Iter    0: loss=5.534123e-02 | grad=2.8345e+00 | lr=8.96e-03
Iter    1: loss=1.233388e-01 | grad=3.0265e+00 | lr=8.96e-03
Iter    2: loss=2.782495e-01 | grad=3.2351e+00 | lr=8.96e-03
Iter    3: loss=4.728368e-02 | grad=5.9778e-01 | lr=8.96e-03
Iter    4: loss=1.729014e-01 | grad=2.9504e+00 | lr=8.96e-03
Iter    5: loss=1.179796e-01 | grad=2.8633e+00 | lr=8.96e-03
Iter    6: loss=6.541470e-02 | grad=1.2024e+00 | lr=8.96e-03
Iter    7: loss=7.343008e-02 | grad=2.7274e+00 | lr=8.96e-03
Iter    8: loss=4.262944e-02 | grad=1.5716e+00 | lr=8.96e-03
Iter    9: loss=5.070205e-02 | grad=2.4328e+00 | lr=8.96e-03
Iter  100: loss=1.259620e-02 | grad=2.0921e+00 | lr=8.96e-03
Iter  200: loss=4.535863e-03 | grad=1.7516e+00 | lr=4.48e-03
Iter  300: loss=3.448835e-03 | grad=1.5466e+00 | lr=4.48e-03
Iter  400: loss=2.409286e-03 | grad=1.2478e+00 | lr=2.24e-03
✓ Saved loss history for timestep 28 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_28.json

 Final loss: 4.325814e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=27/50 (t=0.540)
======================================================================

============================================================
Training timestep n=27 (BACKWARD STEP)
Time: t=0.540, Future models: 23
============================================================
Iter    0: loss=3.154824e-02 | grad=2.9047e+00 | lr=8.91e-03
Iter    1: loss=2.538244e-01 | grad=3.2019e+00 | lr=8.91e-03
Iter    2: loss=6.886709e-02 | grad=1.5917e+00 | lr=8.91e-03
Iter    3: loss=9.962407e-02 | grad=2.4424e+00 | lr=8.91e-03
Iter    4: loss=5.161703e-02 | grad=1.3524e+00 | lr=8.91e-03
Iter    5: loss=9.767312e-02 | grad=1.3519e+00 | lr=8.91e-03
Iter    6: loss=5.266950e-02 | grad=1.1813e+00 | lr=8.91e-03
Iter    7: loss=3.511944e-02 | grad=8.7214e-01 | lr=8.91e-03
Iter    8: loss=5.436365e-02 | grad=2.0339e+00 | lr=8.91e-03
Iter    9: loss=4.099583e-02 | grad=1.5331e+00 | lr=8.91e-03
Iter  100: loss=1.656839e-02 | grad=2.7701e+00 | lr=8.91e-03
Iter  200: loss=2.968751e-03 | grad=4.1186e-01 | lr=4.46e-03
Iter  300: loss=2.517842e-03 | grad=1.9937e+00 | lr=1.11e-03
Iter  400: loss=1.312782e-03 | grad=3.0525e-01 | lr=1.11e-03
✓ Saved loss history for timestep 27 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_27.json

 Final loss: 1.038527e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=26/50 (t=0.520)
======================================================================

============================================================
Training timestep n=26 (BACKWARD STEP)
Time: t=0.520, Future models: 24
============================================================
Iter    0: loss=8.125305e-02 | grad=2.9894e+00 | lr=8.87e-03
Iter    1: loss=1.335446e-01 | grad=3.1770e+00 | lr=8.87e-03
Iter    2: loss=2.405604e-01 | grad=3.4104e+00 | lr=8.87e-03
Iter    3: loss=6.450117e-02 | grad=1.6000e+00 | lr=8.87e-03
Iter    4: loss=1.066634e-01 | grad=2.7222e+00 | lr=8.87e-03
Iter    5: loss=4.990095e-02 | grad=1.4572e+00 | lr=8.87e-03
Iter    6: loss=5.872087e-02 | grad=2.0682e+00 | lr=8.87e-03
Iter    7: loss=4.481420e-02 | grad=1.1915e+00 | lr=8.87e-03
Iter    8: loss=6.567509e-02 | grad=1.6406e+00 | lr=8.87e-03
Iter    9: loss=3.590019e-02 | grad=1.4508e+00 | lr=8.87e-03
Iter  100: loss=6.864133e-03 | grad=1.0658e+00 | lr=8.87e-03
Iter  200: loss=5.763901e-03 | grad=2.7882e+00 | lr=4.43e-03
Iter  300: loss=1.891710e-03 | grad=5.5720e-01 | lr=2.22e-03
Iter  400: loss=1.390516e-03 | grad=7.3369e-01 | lr=1.11e-03
✓ Saved loss history for timestep 26 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_26.json

 Final loss: 1.075971e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=25/50 (t=0.500)
======================================================================

============================================================
Training timestep n=25 (BACKWARD STEP)
Time: t=0.500, Future models: 25
============================================================
Iter    0: loss=5.770021e-02 | grad=3.0672e+00 | lr=8.82e-03
Iter    1: loss=1.539938e-01 | grad=3.2242e+00 | lr=8.82e-03
Iter    2: loss=1.757635e-01 | grad=2.9563e+00 | lr=8.82e-03
Iter    3: loss=5.726130e-02 | grad=2.8199e+00 | lr=8.82e-03
Iter    4: loss=3.240532e-02 | grad=1.8793e+00 | lr=8.82e-03
Iter    5: loss=9.203906e-02 | grad=3.0530e+00 | lr=8.82e-03
Iter    6: loss=4.736988e-02 | grad=1.7471e+00 | lr=8.82e-03
Iter    7: loss=6.769057e-02 | grad=3.0358e+00 | lr=8.82e-03
Iter    8: loss=5.495942e-02 | grad=2.2832e+00 | lr=8.82e-03
Iter    9: loss=3.868478e-02 | grad=1.2098e+00 | lr=8.82e-03
Iter  100: loss=1.055454e-02 | grad=1.9244e+00 | lr=8.82e-03
Iter  200: loss=3.804861e-03 | grad=2.1365e+00 | lr=2.21e-03
Iter  300: loss=2.710606e-03 | grad=2.1440e+00 | lr=2.21e-03
Iter  400: loss=1.686114e-03 | grad=9.8231e-01 | lr=1.10e-03
✓ Saved loss history for timestep 25 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_25.json

 Final loss: 1.331351e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=24/50 (t=0.480)
======================================================================

============================================================
Training timestep n=24 (BACKWARD STEP)
Time: t=0.480, Future models: 26
============================================================
Iter    0: loss=5.730067e-02 | grad=3.1291e+00 | lr=8.78e-03
Iter    1: loss=1.723328e-01 | grad=3.3197e+00 | lr=8.78e-03
Iter    2: loss=1.633461e-01 | grad=3.0349e+00 | lr=8.78e-03
Iter    3: loss=6.850408e-02 | grad=2.8307e+00 | lr=8.78e-03
Iter    4: loss=4.926974e-02 | grad=2.5588e+00 | lr=8.78e-03
Iter    5: loss=7.747485e-02 | grad=3.2278e+00 | lr=8.78e-03
Iter    6: loss=3.882553e-02 | grad=2.3204e+00 | lr=8.78e-03
Iter    7: loss=7.014941e-02 | grad=3.1604e+00 | lr=8.78e-03
Iter    8: loss=6.232115e-02 | grad=3.0993e+00 | lr=8.78e-03
Iter    9: loss=3.256530e-02 | grad=7.7590e-01 | lr=8.78e-03
Iter  100: loss=6.750515e-03 | grad=9.2535e-01 | lr=8.78e-03
Iter  200: loss=1.186158e-02 | grad=3.0059e+00 | lr=4.39e-03
Iter  300: loss=2.352895e-03 | grad=1.1924e-01 | lr=2.19e-03
Iter  400: loss=2.232477e-03 | grad=1.7184e+00 | lr=2.19e-03
✓ Saved loss history for timestep 24 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_24.json

 Final loss: 1.793530e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=23/50 (t=0.460)
======================================================================

============================================================
Training timestep n=23 (BACKWARD STEP)
Time: t=0.460, Future models: 27
============================================================
Iter    0: loss=2.747202e-02 | grad=3.2333e+00 | lr=8.73e-03
Iter    1: loss=1.796234e-01 | grad=3.3675e+00 | lr=8.73e-03
Iter    2: loss=1.272058e-01 | grad=1.9710e+00 | lr=8.73e-03
Iter    3: loss=7.941131e-02 | grad=3.1748e+00 | lr=8.73e-03
Iter    4: loss=5.395377e-02 | grad=1.9600e+00 | lr=8.73e-03
Iter    5: loss=2.208927e-02 | grad=1.6585e+00 | lr=8.73e-03
Iter    6: loss=9.067710e-02 | grad=3.3090e+00 | lr=8.73e-03
Iter    7: loss=5.479360e-02 | grad=1.5933e+00 | lr=8.73e-03
Iter    8: loss=6.008311e-02 | grad=3.1812e+00 | lr=8.73e-03
Iter    9: loss=3.895556e-02 | grad=1.2450e+00 | lr=8.73e-03
Iter  100: loss=4.927870e-03 | grad=1.6301e+00 | lr=4.37e-03
Iter  200: loss=5.787410e-03 | grad=2.8188e+00 | lr=4.37e-03
Iter  300: loss=2.582975e-03 | grad=2.5447e-01 | lr=2.18e-03
Iter  400: loss=1.965219e-03 | grad=1.2741e+00 | lr=1.09e-03
✓ Saved loss history for timestep 23 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_23.json

 Final loss: 1.451507e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=22/50 (t=0.440)
======================================================================

============================================================
Training timestep n=22 (BACKWARD STEP)
Time: t=0.440, Future models: 28
============================================================
Iter    0: loss=8.689253e-02 | grad=3.2781e+00 | lr=8.69e-03
Iter    1: loss=1.060587e-01 | grad=3.4579e+00 | lr=8.69e-03
Iter    2: loss=3.076116e-01 | grad=3.6670e+00 | lr=8.69e-03
Iter    3: loss=4.301080e-02 | grad=8.3493e-01 | lr=8.69e-03
Iter    4: loss=1.851737e-01 | grad=3.4214e+00 | lr=8.69e-03
Iter    5: loss=1.472916e-01 | grad=3.3341e+00 | lr=8.69e-03
Iter    6: loss=5.277845e-02 | grad=2.3677e+00 | lr=8.69e-03
Iter    7: loss=7.138544e-02 | grad=3.2317e+00 | lr=8.69e-03
Iter    8: loss=5.230208e-02 | grad=1.8064e+00 | lr=8.69e-03
Iter    9: loss=7.836662e-02 | grad=2.3869e+00 | lr=8.69e-03
Iter  100: loss=1.030700e-02 | grad=2.3379e+00 | lr=8.69e-03
Iter  200: loss=3.072075e-03 | grad=9.7877e-01 | lr=4.35e-03
Iter  300: loss=2.281064e-03 | grad=7.9785e-01 | lr=2.17e-03
Iter  400: loss=2.154280e-03 | grad=1.7806e+00 | lr=2.17e-03
✓ Saved loss history for timestep 22 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_22.json

 Final loss: 2.324788e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=21/50 (t=0.420)
======================================================================

============================================================
Training timestep n=21 (BACKWARD STEP)
Time: t=0.420, Future models: 29
============================================================
Iter    0: loss=5.475360e-02 | grad=3.3383e+00 | lr=8.65e-03
Iter    1: loss=1.729308e-01 | grad=3.5111e+00 | lr=8.65e-03
Iter    2: loss=1.218592e-01 | grad=3.0987e+00 | lr=8.65e-03
Iter    3: loss=1.037872e-01 | grad=3.2014e+00 | lr=8.65e-03
Iter    4: loss=6.280586e-02 | grad=2.4421e+00 | lr=8.65e-03
Iter    5: loss=8.167604e-02 | grad=3.1731e+00 | lr=8.65e-03
Iter    6: loss=4.741021e-02 | grad=1.8244e+00 | lr=8.65e-03
Iter    7: loss=5.857912e-02 | grad=2.5424e+00 | lr=8.65e-03
Iter    8: loss=5.228950e-02 | grad=2.3614e+00 | lr=8.65e-03
Iter    9: loss=2.968663e-02 | grad=1.7355e+00 | lr=8.65e-03
Iter  100: loss=7.674058e-03 | grad=1.0350e+00 | lr=8.65e-03
Iter  200: loss=2.357629e-03 | grad=2.3303e-01 | lr=4.32e-03
Iter  300: loss=2.862546e-03 | grad=1.8925e+00 | lr=2.16e-03
Iter  400: loss=1.813110e-03 | grad=2.8943e-01 | lr=1.08e-03
✓ Saved loss history for timestep 21 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_21.json

 Final loss: 1.567545e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=20/50 (t=0.400)
======================================================================

============================================================
Training timestep n=20 (BACKWARD STEP)
Time: t=0.400, Future models: 30
============================================================
Iter    0: loss=2.414041e-02 | grad=3.3917e+00 | lr=8.60e-03
Iter    1: loss=1.905614e-01 | grad=3.5511e+00 | lr=8.60e-03
Iter    2: loss=1.426138e-01 | grad=2.5890e+00 | lr=8.60e-03
Iter    3: loss=8.259642e-02 | grad=3.2841e+00 | lr=8.60e-03
Iter    4: loss=4.937911e-02 | grad=9.0246e-01 | lr=8.60e-03
Iter    5: loss=6.464687e-02 | grad=3.3147e+00 | lr=8.60e-03
Iter    6: loss=5.013049e-02 | grad=1.9072e+00 | lr=8.60e-03
Iter    7: loss=4.615906e-02 | grad=2.7474e+00 | lr=8.60e-03
Iter    8: loss=4.636723e-02 | grad=2.9271e+00 | lr=8.60e-03
Iter    9: loss=3.479324e-02 | grad=1.8091e+00 | lr=8.60e-03
Iter  100: loss=7.075245e-03 | grad=1.4519e+00 | lr=8.60e-03
Iter  200: loss=4.889086e-03 | grad=1.1900e+00 | lr=4.30e-03
Iter  300: loss=3.687140e-03 | grad=1.9795e+00 | lr=4.30e-03
Iter  400: loss=2.122740e-03 | grad=1.5226e+00 | lr=2.15e-03
✓ Saved loss history for timestep 20 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_20.json

 Final loss: 1.774361e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=19/50 (t=0.380)
======================================================================

============================================================
Training timestep n=19 (BACKWARD STEP)
Time: t=0.380, Future models: 31
============================================================
Iter    0: loss=8.705230e-02 | grad=3.4763e+00 | lr=8.56e-03
Iter    1: loss=1.531196e-01 | grad=3.6025e+00 | lr=8.56e-03
Iter    2: loss=8.564235e-02 | grad=3.1627e+00 | lr=8.56e-03
Iter    3: loss=1.001458e-01 | grad=3.2692e+00 | lr=8.56e-03
Iter    4: loss=6.114713e-02 | grad=2.9259e+00 | lr=8.56e-03
Iter    5: loss=7.150872e-02 | grad=3.3788e+00 | lr=8.56e-03
Iter    6: loss=4.387151e-02 | grad=2.0976e+00 | lr=8.56e-03
Iter    7: loss=6.373410e-02 | grad=2.9937e+00 | lr=8.56e-03
Iter    8: loss=4.603254e-02 | grad=2.9300e+00 | lr=8.56e-03
Iter    9: loss=3.964846e-02 | grad=2.4908e+00 | lr=8.56e-03
Iter  100: loss=8.260034e-03 | grad=5.9389e-01 | lr=8.56e-03
Iter  200: loss=3.371494e-03 | grad=5.8542e-01 | lr=4.28e-03
Iter  300: loss=3.947627e-03 | grad=1.1317e+00 | lr=4.28e-03
Iter  400: loss=2.021744e-03 | grad=5.0799e-01 | lr=2.14e-03
✓ Saved loss history for timestep 19 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_19.json

 Final loss: 1.954967e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=18/50 (t=0.360)
======================================================================

============================================================
Training timestep n=18 (BACKWARD STEP)
Time: t=0.360, Future models: 32
============================================================
Iter    0: loss=2.082302e-02 | grad=3.1652e+00 | lr=8.52e-03
Iter    1: loss=1.666162e-01 | grad=3.6643e+00 | lr=8.52e-03
Iter    2: loss=1.284996e-01 | grad=2.7527e+00 | lr=8.52e-03
Iter    3: loss=9.029584e-02 | grad=2.5599e+00 | lr=8.52e-03
Iter    4: loss=4.298637e-02 | grad=1.0864e+00 | lr=8.52e-03
Iter    5: loss=9.897810e-02 | grad=3.4244e+00 | lr=8.52e-03
Iter    6: loss=5.270284e-02 | grad=1.0760e+00 | lr=8.52e-03
Iter    7: loss=6.603079e-02 | grad=3.5893e+00 | lr=8.52e-03
Iter    8: loss=3.623562e-02 | grad=1.1881e+00 | lr=8.52e-03
Iter    9: loss=5.231034e-02 | grad=3.3228e+00 | lr=8.52e-03
Iter  100: loss=6.389528e-03 | grad=1.2017e+00 | lr=8.52e-03
Iter  200: loss=7.158181e-03 | grad=3.2176e+00 | lr=4.26e-03
Iter  300: loss=2.359223e-03 | grad=9.7564e-01 | lr=2.13e-03
Iter  400: loss=2.125747e-03 | grad=7.6569e-01 | lr=2.13e-03
✓ Saved loss history for timestep 18 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_18.json

 Final loss: 1.642017e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=17/50 (t=0.340)
======================================================================

============================================================
Training timestep n=17 (BACKWARD STEP)
Time: t=0.340, Future models: 33
============================================================
Iter    0: loss=8.758220e-02 | grad=3.6263e+00 | lr=8.48e-03
Iter    1: loss=1.163503e-01 | grad=3.7220e+00 | lr=8.48e-03
Iter    2: loss=1.857720e-01 | grad=3.6968e+00 | lr=8.48e-03
Iter    3: loss=5.528946e-02 | grad=2.8674e+00 | lr=8.48e-03
Iter    4: loss=5.295069e-02 | grad=3.3331e+00 | lr=8.48e-03
Iter    5: loss=6.567365e-02 | grad=3.2707e+00 | lr=8.48e-03
Iter    6: loss=3.725142e-02 | grad=2.3856e+00 | lr=8.48e-03
Iter    7: loss=5.519019e-02 | grad=3.5285e+00 | lr=8.48e-03
Iter    8: loss=4.237134e-02 | grad=3.2201e+00 | lr=8.48e-03
Iter    9: loss=3.473844e-02 | grad=3.1221e+00 | lr=8.48e-03
Iter  100: loss=9.211222e-03 | grad=2.4532e+00 | lr=8.48e-03
Iter  200: loss=1.380567e-02 | grad=3.4986e+00 | lr=8.48e-03
Iter  300: loss=2.701183e-03 | grad=1.6860e+00 | lr=4.24e-03
Iter  400: loss=3.785740e-03 | grad=1.2683e+00 | lr=4.24e-03
✓ Saved loss history for timestep 17 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_17.json

 Final loss: 1.948620e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=16/50 (t=0.320)
======================================================================

============================================================
Training timestep n=16 (BACKWARD STEP)
Time: t=0.320, Future models: 34
============================================================
Iter    0: loss=5.146953e-02 | grad=3.6833e+00 | lr=8.43e-03
Iter    1: loss=1.483131e-01 | grad=3.7835e+00 | lr=8.43e-03
Iter    2: loss=1.477568e-01 | grad=3.1973e+00 | lr=8.43e-03
Iter    3: loss=9.134650e-02 | grad=3.7310e+00 | lr=8.43e-03
Iter    4: loss=5.613558e-02 | grad=2.0323e+00 | lr=8.43e-03
Iter    5: loss=7.979203e-02 | grad=3.6744e+00 | lr=8.43e-03
Iter    6: loss=2.867214e-02 | grad=2.2143e+00 | lr=8.43e-03
Iter    7: loss=8.048101e-02 | grad=3.7330e+00 | lr=8.43e-03
Iter    8: loss=6.791893e-02 | grad=3.6914e+00 | lr=8.43e-03
Iter    9: loss=2.955151e-02 | grad=1.2342e+00 | lr=8.43e-03
Iter  100: loss=1.214989e-02 | grad=3.4646e+00 | lr=8.43e-03
Iter  200: loss=1.173753e-02 | grad=3.4409e+00 | lr=8.43e-03
Iter  300: loss=2.662697e-03 | grad=1.2655e-01 | lr=4.22e-03
Iter  400: loss=2.189058e-03 | grad=3.3165e-01 | lr=2.11e-03
✓ Saved loss history for timestep 16 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_16.json

 Final loss: 2.748757e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=15/50 (t=0.300)
======================================================================

============================================================
Training timestep n=15 (BACKWARD STEP)
Time: t=0.300, Future models: 35
============================================================
Iter    0: loss=1.820089e-02 | grad=2.3010e+00 | lr=8.39e-03
Iter    1: loss=1.993843e-01 | grad=3.8893e+00 | lr=8.39e-03
Iter    2: loss=9.070560e-02 | grad=2.2429e+00 | lr=8.39e-03
Iter    3: loss=8.962511e-02 | grad=2.4026e+00 | lr=8.39e-03
Iter    4: loss=5.143196e-02 | grad=7.8784e-01 | lr=8.39e-03
Iter    5: loss=5.310111e-02 | grad=3.0021e+00 | lr=8.39e-03
Iter    6: loss=7.054640e-02 | grad=3.4118e+00 | lr=8.39e-03
Iter    7: loss=3.006226e-02 | grad=1.7882e+00 | lr=8.39e-03
Iter    8: loss=8.559199e-02 | grad=3.7967e+00 | lr=8.39e-03
Iter    9: loss=4.879703e-02 | grad=3.4175e+00 | lr=8.39e-03
Iter  100: loss=4.254876e-03 | grad=1.3138e+00 | lr=4.20e-03
Iter  200: loss=3.616397e-03 | grad=1.7636e+00 | lr=4.20e-03
Iter  300: loss=2.907511e-03 | grad=1.8585e+00 | lr=2.10e-03
Iter  400: loss=1.718048e-03 | grad=4.9429e-01 | lr=1.05e-03
✓ Saved loss history for timestep 15 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_15.json

 Final loss: 1.352009e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=14/50 (t=0.280)
======================================================================

============================================================
Training timestep n=14 (BACKWARD STEP)
Time: t=0.280, Future models: 36
============================================================
Iter    0: loss=8.339128e-02 | grad=3.7842e+00 | lr=8.35e-03
Iter    1: loss=1.255733e-01 | grad=3.9239e+00 | lr=8.35e-03
Iter    2: loss=1.623575e-01 | grad=3.7540e+00 | lr=8.35e-03
Iter    3: loss=8.185495e-02 | grad=3.8622e+00 | lr=8.35e-03
Iter    4: loss=4.332294e-02 | grad=2.7891e+00 | lr=8.35e-03
Iter    5: loss=7.939866e-02 | grad=3.7399e+00 | lr=8.35e-03
Iter    6: loss=4.229697e-02 | grad=2.9158e+00 | lr=8.35e-03
Iter    7: loss=7.706241e-02 | grad=3.8425e+00 | lr=8.35e-03
Iter    8: loss=6.639712e-02 | grad=3.7711e+00 | lr=8.35e-03
Iter    9: loss=2.679217e-02 | grad=2.2009e+00 | lr=8.35e-03
Iter  100: loss=7.760759e-03 | grad=2.1178e+00 | lr=8.35e-03
Iter  200: loss=1.315092e-02 | grad=3.5520e+00 | lr=8.35e-03
Iter  300: loss=2.943930e-03 | grad=1.8257e+00 | lr=2.09e-03
Iter  400: loss=1.757179e-03 | grad=1.5134e+00 | lr=2.09e-03
✓ Saved loss history for timestep 14 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_14.json

 Final loss: 1.440757e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=13/50 (t=0.260)
======================================================================

============================================================
Training timestep n=13 (BACKWARD STEP)
Time: t=0.260, Future models: 37
============================================================
Iter    0: loss=4.805010e-02 | grad=3.8252e+00 | lr=8.31e-03
Iter    1: loss=1.532918e-01 | grad=3.9402e+00 | lr=8.31e-03
Iter    2: loss=9.128382e-02 | grad=2.2252e+00 | lr=8.31e-03
Iter    3: loss=1.155989e-01 | grad=3.8965e+00 | lr=8.31e-03
Iter    4: loss=4.334082e-02 | grad=5.5858e-01 | lr=8.31e-03
Iter    5: loss=7.595502e-02 | grad=3.9245e+00 | lr=8.31e-03
Iter    6: loss=4.605949e-02 | grad=2.8915e+00 | lr=8.31e-03
Iter    7: loss=3.735303e-02 | grad=2.8625e+00 | lr=8.31e-03
Iter    8: loss=5.179614e-02 | grad=3.6536e+00 | lr=8.31e-03
Iter    9: loss=3.585701e-02 | grad=2.6048e+00 | lr=8.31e-03
Iter  100: loss=1.521633e-02 | grad=3.7746e+00 | lr=8.31e-03
Iter  200: loss=5.852975e-03 | grad=3.4189e+00 | lr=4.15e-03
Iter  300: loss=1.902226e-03 | grad=1.7365e+00 | lr=2.08e-03
Iter  400: loss=2.615950e-03 | grad=1.5018e+00 | lr=2.08e-03
✓ Saved loss history for timestep 13 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_13.json

 Final loss: 1.151010e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=12/50 (t=0.240)
======================================================================

============================================================
Training timestep n=12 (BACKWARD STEP)
Time: t=0.240, Future models: 38
============================================================
Iter    0: loss=4.517744e-02 | grad=3.8774e+00 | lr=8.27e-03
Iter    1: loss=1.922208e-01 | grad=4.0544e+00 | lr=8.27e-03
Iter    2: loss=6.651711e-02 | grad=1.8533e+00 | lr=8.27e-03
Iter    3: loss=1.264214e-01 | grad=4.0793e+00 | lr=8.27e-03
Iter    4: loss=3.760970e-02 | grad=6.1407e-01 | lr=8.27e-03
Iter    5: loss=8.519623e-02 | grad=3.9420e+00 | lr=8.27e-03
Iter    6: loss=2.554469e-02 | grad=1.4873e+00 | lr=8.27e-03
Iter    7: loss=4.518151e-02 | grad=3.6149e+00 | lr=8.27e-03
Iter    8: loss=4.136200e-02 | grad=3.1622e+00 | lr=8.27e-03
Iter    9: loss=3.093607e-02 | grad=2.6354e+00 | lr=8.27e-03
Iter  100: loss=9.124642e-03 | grad=3.0293e+00 | lr=8.27e-03
Iter  200: loss=2.539073e-03 | grad=1.6937e+00 | lr=2.07e-03
Iter  300: loss=1.672809e-03 | grad=2.2042e+00 | lr=2.07e-03
Iter  400: loss=1.213213e-03 | grad=1.6483e-01 | lr=1.03e-03
✓ Saved loss history for timestep 12 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_12.json

 Final loss: 1.054945e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=11/50 (t=0.220)
======================================================================

============================================================
Training timestep n=11 (BACKWARD STEP)
Time: t=0.220, Future models: 39
============================================================
Iter    0: loss=4.310070e-02 | grad=3.8673e+00 | lr=8.22e-03
Iter    1: loss=1.424195e-01 | grad=4.0560e+00 | lr=8.22e-03
Iter    2: loss=1.331550e-01 | grad=3.7514e+00 | lr=8.22e-03
Iter    3: loss=1.049703e-01 | grad=3.8113e+00 | lr=8.22e-03
Iter    4: loss=6.468640e-02 | grad=3.2960e+00 | lr=8.22e-03
Iter    5: loss=8.681230e-02 | grad=3.9772e+00 | lr=8.22e-03
Iter    6: loss=6.067317e-02 | grad=3.5660e+00 | lr=8.22e-03
Iter    7: loss=5.346091e-02 | grad=3.3617e+00 | lr=8.22e-03
Iter    8: loss=6.210934e-02 | grad=3.8251e+00 | lr=8.22e-03
Iter    9: loss=2.349717e-02 | grad=2.9901e-01 | lr=8.22e-03
Iter  100: loss=1.438382e-02 | grad=3.5960e+00 | lr=8.22e-03
Iter  200: loss=2.511963e-03 | grad=7.0374e-01 | lr=2.06e-03
Iter  300: loss=1.222967e-03 | grad=1.5091e-01 | lr=2.06e-03
Iter  400: loss=1.080928e-03 | grad=1.9083e-01 | lr=1.03e-03
✓ Saved loss history for timestep 11 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_11.json

 Final loss: 1.191340e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=10/50 (t=0.200)
======================================================================

============================================================
Training timestep n=10 (BACKWARD STEP)
Time: t=0.200, Future models: 40
============================================================
Iter    0: loss=1.907704e-02 | grad=1.1654e+00 | lr=8.18e-03
Iter    1: loss=1.912536e-01 | grad=4.1025e+00 | lr=8.18e-03
Iter    2: loss=8.975207e-02 | grad=2.7758e+00 | lr=8.18e-03
Iter    3: loss=7.744353e-02 | grad=1.4800e+00 | lr=8.18e-03
Iter    4: loss=4.020575e-02 | grad=6.2334e-01 | lr=8.18e-03
Iter    5: loss=3.762863e-02 | grad=1.1545e+00 | lr=8.18e-03
Iter    6: loss=5.251268e-02 | grad=3.0848e+00 | lr=8.18e-03
Iter    7: loss=5.880462e-02 | grad=3.4149e+00 | lr=8.18e-03
Iter    8: loss=2.783576e-02 | grad=8.5019e-01 | lr=8.18e-03
Iter    9: loss=6.280930e-02 | grad=4.0929e+00 | lr=8.18e-03
Iter  100: loss=9.733077e-03 | grad=3.7412e+00 | lr=8.18e-03
Iter  200: loss=1.688874e-03 | grad=5.7592e-01 | lr=2.05e-03
Iter  300: loss=1.547753e-03 | grad=3.5918e-01 | lr=2.05e-03
Iter  400: loss=1.340646e-03 | grad=1.8591e+00 | lr=1.02e-03
✓ Saved loss history for timestep 10 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_10.json

 Final loss: 1.037371e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=9/50 (t=0.180)
======================================================================

============================================================
Training timestep n=9 (BACKWARD STEP)
Time: t=0.180, Future models: 41
============================================================
Iter    0: loss=3.869535e-02 | grad=3.8307e+00 | lr=8.14e-03
Iter    1: loss=1.773254e-01 | grad=4.1553e+00 | lr=8.14e-03
Iter    2: loss=8.596212e-02 | grad=2.6772e+00 | lr=8.14e-03
Iter    3: loss=1.160030e-01 | grad=4.1371e+00 | lr=8.14e-03
Iter    4: loss=4.996639e-02 | grad=7.3452e-01 | lr=8.14e-03
Iter    5: loss=8.225030e-02 | grad=3.8442e+00 | lr=8.14e-03
Iter    6: loss=3.340123e-02 | grad=4.9487e-01 | lr=8.14e-03
Iter    7: loss=7.435939e-02 | grad=4.1248e+00 | lr=8.14e-03
Iter    8: loss=2.801277e-02 | grad=2.4327e+00 | lr=8.14e-03
Iter    9: loss=7.644052e-02 | grad=4.1100e+00 | lr=8.14e-03
Iter  100: loss=9.942790e-03 | grad=1.2524e+00 | lr=8.14e-03
Iter  200: loss=1.143561e-02 | grad=3.9706e+00 | lr=4.07e-03
Iter  300: loss=1.665275e-03 | grad=1.2392e+00 | lr=2.04e-03
Iter  400: loss=1.243137e-03 | grad=7.2948e-01 | lr=2.04e-03
✓ Saved loss history for timestep 9 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_9.json

 Final loss: 1.282796e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=8/50 (t=0.160)
======================================================================

============================================================
Training timestep n=8 (BACKWARD STEP)
Time: t=0.160, Future models: 42
============================================================
Iter    0: loss=6.840646e-02 | grad=4.0487e+00 | lr=8.10e-03
Iter    1: loss=1.667375e-01 | grad=4.2171e+00 | lr=8.10e-03
Iter    2: loss=5.599854e-02 | grad=1.2862e+00 | lr=8.10e-03
Iter    3: loss=8.127564e-02 | grad=3.9160e+00 | lr=8.10e-03
Iter    4: loss=6.856358e-02 | grad=4.1071e+00 | lr=8.10e-03
Iter    5: loss=1.890887e-02 | grad=6.4313e-01 | lr=8.10e-03
Iter    6: loss=6.239305e-02 | grad=4.0559e+00 | lr=8.10e-03
Iter    7: loss=4.344876e-02 | grad=1.3291e+00 | lr=8.10e-03
Iter    8: loss=4.176136e-02 | grad=3.3584e+00 | lr=8.10e-03
Iter    9: loss=3.150626e-02 | grad=2.5209e+00 | lr=8.10e-03
Iter  100: loss=7.789077e-03 | grad=3.8025e+00 | lr=4.05e-03
Iter  200: loss=3.142252e-03 | grad=2.6575e+00 | lr=4.05e-03
Iter  300: loss=2.042954e-03 | grad=1.9810e+00 | lr=2.03e-03
Iter  400: loss=1.147548e-03 | grad=8.1458e-01 | lr=1.01e-03
✓ Saved loss history for timestep 8 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_8.json

 Final loss: 1.002089e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=7/50 (t=0.140)
======================================================================

============================================================
Training timestep n=7 (BACKWARD STEP)
Time: t=0.140, Future models: 43
============================================================
Iter    0: loss=3.439713e-02 | grad=3.6262e+00 | lr=8.06e-03
Iter    1: loss=1.351953e-01 | grad=4.2683e+00 | lr=8.06e-03
Iter    2: loss=1.706764e-01 | grad=4.2195e+00 | lr=8.06e-03
Iter    3: loss=6.888609e-02 | grad=3.6090e+00 | lr=8.06e-03
Iter    4: loss=4.856783e-02 | grad=3.5267e+00 | lr=8.06e-03
Iter    5: loss=9.626836e-02 | grad=4.2330e+00 | lr=8.06e-03
Iter    6: loss=6.188050e-02 | grad=3.5546e+00 | lr=8.06e-03
Iter    7: loss=5.092650e-02 | grad=3.9177e+00 | lr=8.06e-03
Iter    8: loss=5.174068e-02 | grad=3.8533e+00 | lr=8.06e-03
Iter    9: loss=3.334440e-02 | grad=1.4600e+00 | lr=8.06e-03
Iter  100: loss=8.267570e-03 | grad=2.7711e+00 | lr=8.06e-03
Iter  200: loss=4.224022e-03 | grad=3.3249e+00 | lr=4.03e-03
Iter  300: loss=6.620939e-03 | grad=4.0569e+00 | lr=4.03e-03
Iter  400: loss=5.611965e-03 | grad=4.0322e+00 | lr=2.02e-03
✓ Saved loss history for timestep 7 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_7.json

 Final loss: 1.183354e-03
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=6/50 (t=0.120)
======================================================================

============================================================
Training timestep n=6 (BACKWARD STEP)
Time: t=0.120, Future models: 44
============================================================
Iter    0: loss=3.226848e-02 | grad=3.4929e+00 | lr=8.02e-03
Iter    1: loss=1.499221e-01 | grad=4.2664e+00 | lr=8.02e-03
Iter    2: loss=1.627785e-01 | grad=3.9629e+00 | lr=8.02e-03
Iter    3: loss=8.946475e-02 | grad=3.6445e+00 | lr=8.02e-03
Iter    4: loss=6.891463e-02 | grad=3.3637e+00 | lr=8.02e-03
Iter    5: loss=5.235790e-02 | grad=3.4875e+00 | lr=8.02e-03
Iter    6: loss=4.195549e-02 | grad=3.4882e+00 | lr=8.02e-03
Iter    7: loss=4.697799e-02 | grad=3.8129e+00 | lr=8.02e-03
Iter    8: loss=4.204506e-02 | grad=3.6588e+00 | lr=8.02e-03
Iter    9: loss=2.937580e-02 | grad=2.4565e+00 | lr=8.02e-03
Iter  100: loss=9.098904e-03 | grad=3.5452e+00 | lr=8.02e-03
Iter  200: loss=1.935168e-03 | grad=2.1991e+00 | lr=2.01e-03
Iter  300: loss=1.111140e-03 | grad=1.0776e+00 | lr=2.01e-03
Iter  400: loss=9.920672e-04 | grad=6.4064e-01 | lr=1.00e-03
✓ Saved loss history for timestep 6 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_6.json

 Final loss: 9.345259e-04
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=5/50 (t=0.100)
======================================================================

============================================================
Training timestep n=5 (BACKWARD STEP)
Time: t=0.100, Future models: 45
============================================================
Iter    0: loss=2.196950e-02 | grad=4.5252e-01 | lr=7.98e-03
Iter    1: loss=6.233737e-02 | grad=2.6797e+00 | lr=7.98e-03
Iter    2: loss=2.264713e-01 | grad=4.2619e+00 | lr=7.98e-03
Iter    3: loss=6.007440e-02 | grad=3.6126e+00 | lr=7.98e-03
Iter    4: loss=1.912105e-01 | grad=4.5000e+00 | lr=7.98e-03
Iter    5: loss=1.002706e-01 | grad=8.5167e-01 | lr=7.98e-03
Iter    6: loss=1.031352e-01 | grad=4.2074e+00 | lr=7.98e-03
Iter    7: loss=5.177497e-02 | grad=4.2920e+00 | lr=7.98e-03
Iter    8: loss=3.979518e-02 | grad=3.4699e+00 | lr=7.98e-03
Iter    9: loss=5.436219e-02 | grad=4.0377e+00 | lr=7.98e-03
Iter  100: loss=1.042194e-02 | grad=4.1277e+00 | lr=3.99e-03
Iter  200: loss=2.251323e-03 | grad=3.8019e-01 | lr=2.00e-03
Iter  300: loss=1.433596e-03 | grad=2.3459e+00 | lr=2.00e-03
Iter  400: loss=9.807682e-04 | grad=3.0358e-01 | lr=9.98e-04
✓ Saved loss history for timestep 5 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_5.json

 Final loss: 8.996400e-04
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=4/50 (t=0.080)
======================================================================

============================================================
Training timestep n=4 (BACKWARD STEP)
Time: t=0.080, Future models: 46
============================================================
Iter    0: loss=5.415663e-02 | grad=4.1338e+00 | lr=7.94e-03
Iter    1: loss=1.118652e-01 | grad=4.3227e+00 | lr=7.94e-03
Iter    2: loss=2.394127e-01 | grad=4.3090e+00 | lr=7.94e-03
Iter    3: loss=5.611551e-02 | grad=1.5246e+00 | lr=7.94e-03
Iter    4: loss=1.305289e-01 | grad=4.3403e+00 | lr=7.94e-03
Iter    5: loss=5.147491e-02 | grad=2.7843e+00 | lr=7.94e-03
Iter    6: loss=1.155848e-01 | grad=4.4195e+00 | lr=7.94e-03
Iter    7: loss=7.439390e-02 | grad=4.2686e+00 | lr=7.94e-03
Iter    8: loss=5.613358e-02 | grad=3.8702e+00 | lr=7.94e-03
Iter    9: loss=7.002816e-02 | grad=4.2543e+00 | lr=7.94e-03
Iter  100: loss=2.119556e-02 | grad=4.1933e+00 | lr=7.94e-03
Iter  200: loss=2.934807e-03 | grad=3.2883e+00 | lr=3.97e-03
Iter  300: loss=1.450711e-03 | grad=3.4405e-01 | lr=1.99e-03
Iter  400: loss=9.288308e-04 | grad=5.9235e-01 | lr=9.93e-04
✓ Saved loss history for timestep 4 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_4.json

 Final loss: 8.641797e-04
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=3/50 (t=0.060)
======================================================================

============================================================
Training timestep n=3 (BACKWARD STEP)
Time: t=0.060, Future models: 47
============================================================
Iter    0: loss=2.772099e-02 | grad=2.9098e+00 | lr=7.90e-03
Iter    1: loss=2.021185e-01 | grad=4.4183e+00 | lr=7.90e-03
Iter    2: loss=6.927630e-02 | grad=1.4326e+00 | lr=7.90e-03
Iter    3: loss=4.009220e-02 | grad=2.6822e+00 | lr=7.90e-03
Iter    4: loss=9.877460e-02 | grad=4.2931e+00 | lr=7.90e-03
Iter    5: loss=4.009009e-02 | grad=2.2775e+00 | lr=7.90e-03
Iter    6: loss=1.971282e-02 | grad=2.9981e+00 | lr=7.90e-03
Iter    7: loss=8.974063e-02 | grad=4.2982e+00 | lr=7.90e-03
Iter    8: loss=5.493568e-02 | grad=3.7553e+00 | lr=7.90e-03
Iter    9: loss=5.110325e-02 | grad=3.6247e+00 | lr=7.90e-03
Iter  100: loss=6.437562e-03 | grad=3.1464e+00 | lr=7.90e-03
Iter  200: loss=5.581417e-03 | grad=3.9696e+00 | lr=3.95e-03
Iter  300: loss=2.719645e-03 | grad=1.9135e+00 | lr=3.95e-03
Iter  400: loss=2.653671e-03 | grad=3.9297e+00 | lr=9.88e-04
✓ Saved loss history for timestep 3 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_3.json

 Final loss: 9.258678e-04
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=2/50 (t=0.040)
======================================================================

============================================================
Training timestep n=2 (BACKWARD STEP)
Time: t=0.040, Future models: 48
============================================================
Iter    0: loss=2.632723e-02 | grad=2.6609e+00 | lr=7.86e-03
Iter    1: loss=1.616465e-01 | grad=4.4046e+00 | lr=7.86e-03
Iter    2: loss=1.406597e-01 | grad=3.5027e+00 | lr=7.86e-03
Iter    3: loss=5.438729e-02 | grad=3.4007e+00 | lr=7.86e-03
Iter    4: loss=3.808313e-02 | grad=1.0210e+00 | lr=7.86e-03
Iter    5: loss=3.096547e-02 | grad=2.7714e+00 | lr=7.86e-03
Iter    6: loss=6.589486e-02 | grad=4.3798e+00 | lr=7.86e-03
Iter    7: loss=3.879452e-02 | grad=7.4651e-01 | lr=7.86e-03
Iter    8: loss=4.960477e-02 | grad=4.1919e+00 | lr=7.86e-03
Iter    9: loss=2.075768e-02 | grad=2.0996e+00 | lr=7.86e-03
Iter  100: loss=3.587520e-03 | grad=5.0463e-01 | lr=7.86e-03
Iter  200: loss=4.668219e-03 | grad=3.8486e+00 | lr=3.93e-03
Iter  300: loss=1.646343e-03 | grad=3.0806e+00 | lr=1.97e-03
Iter  400: loss=8.143595e-04 | grad=1.3842e-01 | lr=9.83e-04
✓ Saved loss history for timestep 2 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_2.json

 Final loss: 8.321957e-04
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=1/50 (t=0.020)
======================================================================

============================================================
Training timestep n=1 (BACKWARD STEP)
Time: t=0.020, Future models: 49
============================================================
Iter    0: loss=2.469913e-02 | grad=2.3087e+00 | lr=7.82e-03
Iter    1: loss=1.869423e-01 | grad=4.4388e+00 | lr=7.82e-03
Iter    2: loss=6.396475e-02 | grad=3.2049e+00 | lr=7.82e-03
Iter    3: loss=9.821114e-02 | grad=4.4576e+00 | lr=7.82e-03
Iter    4: loss=3.724558e-02 | grad=1.2230e+00 | lr=7.82e-03
Iter    5: loss=5.672601e-02 | grad=4.1961e+00 | lr=7.82e-03
Iter    6: loss=3.232672e-02 | grad=2.6868e+00 | lr=7.82e-03
Iter    7: loss=3.187687e-02 | grad=3.5365e+00 | lr=7.82e-03
Iter    8: loss=3.818757e-02 | grad=4.1714e+00 | lr=7.82e-03
Iter    9: loss=1.925567e-02 | grad=3.0142e+00 | lr=7.82e-03
Iter  100: loss=7.856680e-03 | grad=3.8683e+00 | lr=7.82e-03
Iter  200: loss=4.960750e-03 | grad=3.9698e+00 | lr=3.91e-03
Iter  300: loss=3.495455e-03 | grad=4.1623e+00 | lr=9.78e-04
Iter  400: loss=7.941594e-04 | grad=1.5356e-01 | lr=9.78e-04
✓ Saved loss history for timestep 1 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_1.json

 Final loss: 7.799471e-04
Iterations used: 500

======================================================================
TRAINING TIMESTEP n=0/50 (t=0.000)
======================================================================

============================================================
Training timestep n=0 (BACKWARD STEP)
Time: t=0.000, Future models: 50
============================================================
Iter    0: loss=2.356100e-02 | grad=1.9412e+00 | lr=7.78e-03
Iter    1: loss=1.591249e-01 | grad=4.4241e+00 | lr=7.78e-03
Iter    2: loss=1.250180e-01 | grad=4.2221e+00 | lr=7.78e-03
Iter    3: loss=7.262997e-02 | grad=4.4488e+00 | lr=7.78e-03
Iter    4: loss=2.529493e-02 | grad=6.1606e-01 | lr=7.78e-03
Iter    5: loss=5.606027e-02 | grad=4.2373e+00 | lr=7.78e-03
Iter    6: loss=1.551074e-02 | grad=7.8920e-01 | lr=7.78e-03
Iter    7: loss=5.835434e-02 | grad=4.4318e+00 | lr=7.78e-03
Iter    8: loss=2.644683e-02 | grad=2.1948e+00 | lr=7.78e-03
Iter    9: loss=4.654556e-02 | grad=4.2982e+00 | lr=7.78e-03
Iter  100: loss=2.154034e-02 | grad=4.3392e+00 | lr=7.78e-03
Iter  200: loss=3.430824e-03 | grad=4.2071e+00 | lr=1.95e-03
Iter  300: loss=7.683125e-04 | grad=1.3953e-01 | lr=9.73e-04
Iter  400: loss=7.764221e-04 | grad=1.3682e+00 | lr=9.73e-04
✓ Saved loss history for timestep 0 to /cfs/klemming/projects/supr/naiss2024-22-1707/DeepBSVIE/linear1_2025-11-15_16-53-07/models/loss_history_timestep_0.json

 Final loss: 7.093530e-04
Iterations used: 500
Elapsed time: 9.0331 minutes

======================================================================
VALIDATING AGAINST ANALYTICAL SOLUTION
======================================================================

Computing Z predictions and analytical values...

======================================================================
VALIDATION METRICS
======================================================================
Y - Overall MSE:         2.896012e-04
----------------------------------------------------------------------
Z - Overall MSE:         1.191318e-05
======================================================================
